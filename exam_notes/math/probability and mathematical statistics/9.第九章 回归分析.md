### ** 学习建议**
本章介绍回归分析，用于研究变量之间的相关关系并建立数学模型进行预测和控制。它是数理统计中极具应用价值的部分，核心是通过数据建立因变量与自变量之间的定量关系式。
- **核心重点（★★★★★ 和 ★★★★☆）**：9.1, 9.2, 9.3, 9.6 节是重中之重。必须深刻理解最小二乘原理，掌握一元和多元线性回归模型的建立、检验与应用。
- **理解关键（★★★☆☆）**：9.4, 9.5 节是回归分析的应用和扩展，需要理解其思想和方法。
- **核心思路**：本章遵循“散点图观察 -> 建立模型 -> 参数估计（最小二乘） -> 模型检验（显著性检验） -> 预测与控制”的基本流程。

---
### 9.1 回归分析的基本概念与最小二乘法 ★★★★★
- **基本概念**：
    - **回归分析**：研究一个或多个自变量（解释变量）与一个因变量（响应变量）之间依存关系的统计方法。
    - **相关关系**：变量间非确定性的依存关系，区别于函数关系。
- **最小二乘法原理**：
    - **核心思想**：寻找参数估计值，使得**残差平方和**（观测值与估计值之差的平方和）达到最小。
    - 对于一元线性模型 $y = a + bx + \varepsilon$，目标是最小化 $Q(a, b) = \sum_{i=1}^n (y_i - a - bx_i)^2$。
    - **求解**：分别对 $a$ 和 $b$ 求偏导并令其为零，得到**正规方程组**，解出参数估计值 $\hat{a}$ 和 $\hat{b}$。
- **高斯-马尔可夫定理**：在经典线性回归假设下，最小二乘估计量是最优线性无偏估计量(BLUE)。

### 9.2 线性回归方程 ★★★★★
- **一元线性回归模型**：
    - $y = a + bx + \varepsilon$，其中 $\varepsilon \sim N(0, \sigma^2)$ 为随机误差。
    - **参数估计（最小二乘估计）**：
        - 回归系数：$\hat{b} = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2} = \frac{L_{xy}}{L_{xx}}$
        - 截距项：$\hat{a} = \bar{y} - \hat{b}\bar{x}$
    - **回归方程**：$\hat{y} = \hat{a} + \hat{b}x$
- **离差平方和分解**：
    - 总离差平方和：$S_T = L_{yy} = \sum (y_i - \bar{y})^2$
    - 回归平方和：$S_R = \sum (\hat{y}_i - \bar{y})^2 = \hat{b}^2 L_{xx}$
    - 残差平方和：$S_E = \sum (y_i - \hat{y}_i)^2 = S_T - S_R$
    - 关系：$S_T = S_R + S_E$

### 9.3 线性相关的显著性检验 ★★★★☆
- **目的**：检验自变量 $x$ 与因变量 $y$ 之间是否存在显著的线性关系。
- **相关系数检验**：
    - **样本相关系数**：$r = \frac{L_{xy}}{\sqrt{L_{xx} L_{yy}}}$，其中 $|r| \leq 1$。
    - **检验统计量**：$T = \frac{r\sqrt{n-2}}{\sqrt{1-r^2}} \sim t(n-2)$ （在总体相关系数 $\rho=0$ 的假设下）。
    - **拒绝域**：$|T| > t_{\alpha/2}(n-2)$。
- **方差分析检验（F检验）**：
    - **原假设** $H_0: b=0$ （即 $x$ 与 $y$ 无线性关系）。
    - **检验统计量**：$F = \frac{S_R / 1}{S_E / (n-2)} = \frac{MS_R}{MS_E} \sim F(1, n-2)$。
    - **拒绝域**：$F > F_\alpha(1, n-2)$。
    - **关系**：在一元线性回归中，$F = T^2$，两种检验等价。
- **回归系数的t检验**：
    - 检验 $H_0: b=0$，统计量 $T = \frac{\hat{b}}{S_e / \sqrt{L_{xx}}} \sim t(n-2)$，其中 $S_e = \sqrt{S_E/(n-2)}$ 为剩余标准差。

### 9.4 利用线性回归方程预测与控制 ★★★☆☆
- **预测**：给定自变量 $x = x_0$，预测因变量 $y_0$ 的取值。
    - **点预测**：$\hat{y}_0 = \hat{a} + \hat{b}x_0$。
    - **区间预测**：
        - **均值 $E(y_0)$ 的区间估计**：$\hat{y}_0 \pm t_{\alpha/2}(n-2) \cdot S_e \sqrt{\frac{1}{n} + \frac{(x_0-\bar{x})^2}{L_{xx}}}$。
        - **个体值 $y_0$ 的预测区间**：$\hat{y}_0 \pm t_{\alpha/2}(n-2) \cdot S_e \sqrt{1 + \frac{1}{n} + \frac{(x_0-\bar{x})^2}{L_{xx}}}$。
        - 预测区间比置信区间更宽。
- **控制**：要求 $y$ 在区间 $(y_L, y_U)$ 内，反解出 $x$ 的控制范围。这是预测的逆问题。

### 9.5 曲线回归分析 ★★★☆☆
- **基本思想**：通过变量变换，将非线性关系转化为线性关系进行处理。
- **常用可线性化的曲线类型**：
    - **幂函数**：$y = ax^b$ -> 取对数：$\ln y = \ln a + b \ln x$。
    - **指数函数**：$y = ae^{bx}$ -> 取对数：$\ln y = \ln a + bx$。
    - **对数函数**：$y = a + b \ln x$ -> 令 $x' = \ln x$。
    - **S型曲线**：$y = \frac{1}{a+be^{-x}}$ -> 令 $y' = 1/y, x' = e^{-x}$。
- **步骤**：选择曲线类型 -> 变量变换 -> 线性回归 -> 变换回原变量 -> 检验拟合优度（如相关指数 $R^2$）。

### 9.6 多元线性回归分析 ★★★★★
- **多元线性回归模型**：
    - $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \varepsilon$，其中 $\varepsilon \sim N(0, \sigma^2)$。
- **参数估计（最小二乘）**：
    - 目标：最小化 $Q = \sum (y_i - \hat{y}_i)^2$。
    - 通过求解正规方程组 $X^T X \hat{\beta} = X^T Y$ 得到参数估计值 $\hat{\beta}$。
- **显著性检验**：
    - **回归方程显著性检验（F检验）**：
        - $H_0: \beta_1 = \beta_2 = \cdots = \beta_p = 0$。
        - $F = \frac{S_R / p}{S_E / (n-p-1)} \sim F(p, n-p-1)$。
    - **回归系数显著性检验（t检验）**：
        - 检验单个自变量 $x_j$ 是否显著，$H_0: \beta_j = 0$。
        - $T = \frac{\hat{\beta}_j}{S_e \sqrt{c_{jj}}} \sim t(n-p-1)$，其中 $c_{jj}$ 是 $(X^T X)^{-1}$ 的第 $j$ 个对角元。
- **拟合优度**：
    - **复相关系数**：$R = \sqrt{\frac{S_R}{S_T}}$，衡量所有自变量与因变量的线性关系强度。
    - **决定系数**：$R^2 = \frac{S_R}{S_T}$，表示回归方程对因变量变异的解释比例。

