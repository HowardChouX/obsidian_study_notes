### **学习建议**
本章的核心是从“分布”过渡到“特征数”，用几个关键的数字来概括随机变量的主要统计特性，是连接概率论与统计推断的桥梁。
- **核心重点（★★★★★ 和 ★★★★☆）**：3.1, 3.2, 3.4, 3.5, 3.7, 3.8 节是重中之重。数学期望和方差是最基本、最常用的数字特征，必须熟练掌握其定义、性质和计算。
- **理解关键（★★★☆☆）**：3.3, 3.6 节是核心概念的深化和扩展，需要理解其思想和方法。
- **核心思路**：本章介绍了描述随机变量“平均水平”（期望）、“波动程度”（方差）、“线性关系”（协方差与相关系数）的指标，并引出了理论统计的基石——大数定律。

---
### 3.1 数学期望 ★★★★★
- **定义**：又称均值，是随机变量所有可能取值以其概率为权的加权平均，表示随机变量取值的“中心位置”或“平均水平”。
    - **离散型**：若级数 $\sum_{k=1}^{\infty} x_k p_k$ 绝对收敛，则 $E(X) = \sum_{k=1}^{\infty} x_k p_k$。
    - **连续型**：若积分 $\int_{-\infty}^{+\infty} x f(x) dx$ 绝对收敛，则 $E(X) = \int_{-\infty}^{+\infty} x f(x) dx$。
- **物理意义**：大量重复试验中随机变量取值的算术平均的稳定值。

### 3.2 随机变量函数的数学期望 ★★★★☆
- **定理**：无需求出 $Y=g(X)$ 的分布，可直接由 $X$ 的分布求 $E(Y)$。
    - **离散型**：$E[g(X)] = \sum_{k=1}^{\infty} g(x_k) p_k$。
    - **连续型**：$E[g(X)] = \int_{-\infty}^{+\infty} g(x) f(x) dx$。
- **推广至二维**：对 $Z=g(X, Y)$，有 $E[g(X, Y)] = \iint_{-\infty}^{+\infty} g(x, y) f(x, y) dx dy$（连续型）。

### 3.3 关于数学期望的定理 ★★★☆☆
- **线性性质**：设 $C$ 为常数，则
    1. $E(C) = C$。
    2. $E(CX) = C E(X)$。
    3. $E(X+Y) = E(X) + E(Y)$。
    - **综合**：$E(aX + bY + c) = aE(X) + bE(Y) + c$。
- **重要性**：期望的线性性质是概率计算中最常用、最重要的工具之一。

### 3.4 方差与标准差 ★★★★★
- **方差定义**：衡量随机变量取值与其数学期望的偏离程度。$D(X) = Var(X) = E\{[X - E(X)]^2\}$。
- **计算公式**：$D(X) = E(X^2) - [E(X)]^2$。（常用计算式）
- **标准差**：方差的算术平方根，$\sigma(X) = \sqrt{D(X)}$，与随机变量有相同的量纲。
- **性质**：
    1. $D(C) = 0$。
    2. $D(CX) = C^2 D(X)$。
    3. 若 $X, Y$ 相互独立，则 $D(X+Y) = D(X) + D(Y)$。

### 3.5 某些常用分布的数学期望与方差 ★★★★★
- **0-1分布 $B(1, p)$**：$E(X)=p$, $D(X)=p(1-p)$。
- **二项分布 $B(n, p)$**：$E(X)=np$, $D(X)=np(1-p)$。
- **泊松分布 $P(\lambda)$**：$E(X)=\lambda$, $D(X)=\lambda$。
- **均匀分布 $U(a, b)$**：$E(X)=\frac{a+b}{2}$, $D(X)=\frac{(b-a)^2}{12}$。
- **指数分布 $Exp(\lambda)$**：$E(X)=\frac{1}{\lambda}$, $D(X)=\frac{1}{\lambda^2}$。
- **正态分布 $N(\mu, \sigma^2)$**：$E(X)=\mu$, $D(X)=\sigma^2$。
- **重要性**：这些结论必须牢记，能极大简化计算。

### 3.6 原点矩与中心矩 ★★★☆☆
- **原点矩**：$k$ 阶原点矩 $\nu_k = E(X^k)$。一阶原点矩就是数学期望。
- **中心矩**：$k$ 阶中心矩 $\mu_k = E\{[X - E(X)]^k\}$。二阶中心矩就是方差。
- **作用**：更高阶的矩描述了分布的其他形状特征，如三阶中心矩与分布的偏度有关，四阶中心矩与分布的峰度有关。

### 3.7 协方差与相关系数 ★★★★☆
- **协方差**：衡量两个随机变量变化趋势的统计量。$Cov(X, Y) = E\{[X - E(X)][Y - E(Y)]\}$。
    - **计算式**：$Cov(X, Y) = E(XY) - E(X)E(Y)$。
    - **性质**：1. $Cov(X, Y) = Cov(Y, X)$。 2. $Cov(aX, bY) = ab Cov(X, Y)$。 3. $Cov(X_1+X_2, Y) = Cov(X_1, Y) + Cov(X_2, Y)$。
- **相关系数**：对协方差进行标准化，消除量纲影响。$\rho_{XY} = \frac{Cov(X, Y)}{\sqrt{D(X)} \sqrt{D(Y)}}$。
    - **性质**：$|\rho_{XY}| \leq 1$。$|\rho_{XY}|=1$ 的充要条件是 $X$ 与 $Y$ 以概率1存在线性关系。
    - **含义**：$\rho_{XY}$ 衡量 $X$ 与 $Y$ 之间**线性关系**的强度和方向。

### 3.8 切比雪夫不等式与大数定律 ★★★★★
- **切比雪夫不等式**：对任意 $\epsilon > 0$，有 $P\{|X - E(X)| \geq \epsilon\} \leq \frac{D(X)}{\epsilon^2}$。
    - **意义**：给出了随机变量偏离其期望值的概率的上界，仅用期望和方差即可估计。
- **大数定律**：描述了大量重复试验中随机现象的稳定性。
    - **切比雪夫大数定律**：设 $X_1, X_2, ..., X_n, ...$ 是相互独立的随机变量序列，各有数学期望 $E(X_i)$ 和方差 $D(X_i)$，且方差有共同上界。则对任意 $\epsilon > 0$，有 $\lim_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^{n}X_i - \frac{1}{n}\sum_{i=1}^{n}E(X_i)| < \epsilon\} = 1$。
    - **伯努利大数定律**：是切比雪夫大数定律的特例，描述了频率稳定于概率。
    - **意义**：大数定律是数理统计中用样本均值估计总体均值的理论基石。